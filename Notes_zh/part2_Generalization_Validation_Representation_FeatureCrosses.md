### 5.泛化

#### 判断模型出色与否

理论上：泛化理论（略）

直觉上：奥卡姆剃刀（越简单越好）

经验上：用测试集上的表现作为新数据的预测



前提假设：

- 样本独立同分布
- 分布是平稳的
- 始终从同一分布中抽取样本



### 6.验证

为了防止对测试集的过拟合，将数据集分为三个子集（新增一个验证集）

![](https://github.com/Dinghow/MyRoadToMachineLearning/raw/master/note/img/google-2.jpg)



### 7.表示法

#### 特征工程

定义：将原始数据转化为特征矢量

![](https://github.com/Dinghow/MyRoadToMachineLearning/raw/master/note/img/google-3.jpg)

对于一些无法直接转化为数字的数据（如字符串），通过映射，独热编码转化：

- 首先，为您要表示的所有特征的字符串值定义一个**词汇表**

- 然后，使用该词汇表创建一个**独热（one-hot）编码**（使用N位状态寄存器对N个状态进行编码），用于将指定字符串值表示为一个二元矢量。在该矢量（与指定的字符串值对应）中：

  - 只有一个元素设为 `1`。
  - 其他所有元素均设为 `0`。

  该矢量的长度等于词汇表中的元素数

对于分类值

分类特征具有一组离散的可能值，通常将每个分类特征表示为单独的`bool`值（是a吗？是b吗？），该方法同时有利于多分类情况

#### 良好特征具备的特性：

- 特征值以非零值形式在数据集中多次出现
- 特征应该具有清晰明确的含义
- 特征值的取值范围应该合理（如时间不要取-1）
- 特征的定义不随时间而变化（即平稳性）
- 分布不应包含离谱的离群值

#### 清理数据

**良好的机器学习依赖于良好的数据**，数据的重要性大于模型

##### 缩放特征值：

将浮点特征值从自然范围转换为标准范围

作用：

- 帮助梯度下降法更快收敛
- 帮助避免NaN陷阱（模型中的一个数字在训练期间变成 [NaN](https://en.wikipedia.org/wiki/NaN)，这会导致模型中的很多或所有其他数字最终也会变成 NaN）
- 帮助模型更好确定合适的权重

方法有：

- 线性映射
- 计算Z得分（scaled value = (value - mean) / stddev）

##### 处理极端离群值

- 取对数
- 设上限（可能造成上限出现峰值）

##### 分箱

某些特征值需要分箱处理后才能与标签值建立更好的预测模型（如房价与纬度没有线性关系，但在某一纬度范围内是可以预测的）

##### 清查

处理数据集时要将不可靠的样本给移出或修正



### 8.特征组合

定义：通过将两个或多个输入特征相乘来对特征空间中的**非线性**规律进行编码的合成特征

种类：如[A x B],[A x B x C],[A x A]

学习高度复杂模型：

- 对大规模数据集使用特征组合
- 神经网络

